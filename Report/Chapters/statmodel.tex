\section{Statistical Models}
\label{ch:statmodel}

Primary source for this was Hyndman-et-al-2018 \cite{Hyndman-et-al-2018}.

Some of our statistical models require \textit{homoscedasticity}, i.e., that the model errors are identically distributed with the same variance $\sigma^2$.

We can check this by plotting histograms and checking that they are centred around zero and approximately fit the overlaying normal curve.

\begin{figure}[H]
\minipage{0.33\textwidth}
  \includegraphics[width=\linewidth]{Ireland-residuals.pdf} \label{fig:ireland-residuals}
\endminipage\hfill
\minipage{0.33\textwidth}
  \includegraphics[width=\linewidth]{Italy-residuals.pdf} \label{fig:italy-residuals}
\endminipage\hfill
\minipage{0.33\textwidth}
  \includegraphics[width=\linewidth]{United States-residuals.pdf} \label{fig:usa-residuals}
\endminipage\hfill
\caption{Normality checks, Ireland, Italy and United States}
\end{figure}

\subsection{Holt-Winters’ seasonal method}

\subsubsection{Definitions and Theory}

\begin{figure}[H]
\begin{tcolorbox}[width=.6\textwidth]%

Suppose there are $N$ observations.

Initial step:

$\left|\begin{array}{l}
L_s = \frac1s \sum_{i=1}^s x_i \\
b_s = \frac1s \left[\frac{x_{s+1}-x_1}{s}+\frac{x_{s+2}-x_2}{s}+\dots+\frac{x_{2s}-x_s}{s}\right]\\
S_n  = x_n-L_s, \ n=1,\dots,s
\end{array}\right.$

and choose parameters $0\leq\alpha\leq1,\ 0\leq\beta\leq1$ and $0\leq\gamma\leq1$

Then compute for $s<n\leq N$:

$\left|\begin{array}{lll}
\text{Level} &       L_n & = \alpha (x_n-S_{n-s})+(1-\alpha)(L_{n-1}+b_{n-1})\\
\text{Trend} &      b_n & = \beta(L_n-L_{n-1})+(1-\beta)b_{n-1}\\
\text{Seasonal} & S_n & = \gamma (x_n-L_n) + (1-\gamma)S_{n-s}\\
\text{Forecast} & F_{n+1} & = L_n+b_n+S_{n+1-s}
\end{array}\right.$
For subsequent observations,

$F_{N+k}=L_N+k\cdot b_N+S_{N+k-s}$
\label{SHWx}
\end{tcolorbox}
\caption{Seasonal Holt Winter’s Additive Model Algorithm (denoted SHW$_{+}$)}
\end{figure}


\subsubsection{How to select the best model}

\subsubsection{Forecasting}

\subsubsection{Implementation in R}

\begin{lstlisting}[frame=single, caption = {Algorithm for HoltWinters Model}]
#' dat_ts A time-series of the ovservations x_n
#' countrydat A data.frame with the required info to plot case numbers
#' modeldat A data.frame with model data to plot (has forecastlen more rows than countrydat)
#' cols A list of colours for plotting
#' labs A list of labels for plotting
#' forecastlen The forecast length 
#' q The parameter for the basic model, in order tohave statistical models comparable with mathematical models
#' prevcases The cumulative cases prior to the first day in the range of countrydat

    #lambda=0 ensures values stay positive
    hwfcst     <- forecast::hw(dat_ts, h = forecastlen, seasonal = hwmethod, lambda = 0)
    #ensure first q values are equal to the actual data
    hwfcst$fitted[1:q] <- countrydat$xn[1:q]
    modeldat$hwxn <- c(hwfcst$fitted, hwfcst$mean)
    modeldat$hwlo <- c(hwfcst$fitted, hwfcst$lower[,2])
    modeldat$hwhi <- c(hwfcst$fitted, hwfcst$upper[,2])
    
    modeldat$hwyn  <- xntoyn(modeldat$hwxn)+prevcases
    modeldat$hwylo <- xntoyn(modeldat$hwlo)+prevcases
    modeldat$hwyhi <- xntoyn(modeldat$hwhi)+prevcases
    
    hwnorm <- modnorm(countrydat$xn,hwfcst$fitted)

    labs$hw   <- paste0("HoltWinters algorithm,  ||x*-x||=", modnorm(countrydat$xn,hwfcst$fitted))
    labs$hwy  <- paste0("HoltWinters algorithm,  ||y*-y||=", modnorm(countrydat$yn,modeldat$hwyn[1:nrow(countrydat)]))
    labs$hwpi <- "HW 95% Prediction Interval"
    
    plots[["hw"]]  <- plot_hw(countrydat, modeldat, cols, labs)
    plots[["hwy"]] <- plot_hwy(countrydat, modeldat, cols, labs)
\end{lstlisting}

and our plotting function for daily cases looks like the following

\begin{lstlisting}[frame=single, caption = {Plot HoltWinters Model}]
plot_hw <- function(countrydat, modeldat, cols, labs){
  p <- ggplot(countrydat, binwidth = 0) + 
    geom_bar(aes(x = date, y = xn, fill = "actual"), stat = "identity") + 
    geom_ribbon(data = modeldat, aes(x = date, ymin = hwlo, ymax = hwhi, fill = "hw"), alpha = 0.5) +
    geom_point(data = modeldat, aes(x = date, y = hwxn, colour = "hw")) + 
    geom_line(data = modeldat, aes(x = date, y = hwxn, colour = "hw")) +
    geom_point(data = modeldat, aes(x = date, y = basexn, colour = "base")) + 
    geom_line(data = modeldat, aes(x = date, y = basexn, colour = "base")) +
    geom_point(data = modeldat,aes(x = date, y = modxPeriodic, colour = "periodic")) +
    geom_line(data = modeldat, aes(x = date, y = modxPeriodic, colour = "periodic")) +
    gg_scale_xy + 
    guides(colour=guide_legend(ncol=1,nrow=3,byrow=TRUE),
           fill=guide_legend(ncol=1,nrow=2,byrow=TRUE)) +
    scale_fill_manual(labels = c("actual" = labs$xn, "hw" = labs$hwpi),
                      values = c("actual" = cols$xn, "hw" = cols$hwpi))+ 
    scale_colour_manual(labels = c("base" = labs$basexn, "hw" = labs$hw, "periodic" = labs$periodic),
                        values = c("base" = cols$basexn, "hw" = cols$hw, "periodic" = cols$periodic)
                        ) +
    xntheme()
  return(p)
}

\end{lstlisting}

\subsubsection{Plots}

We see that the additive seasonal method is a better choice for both model fit and confidence interval size.

\begin{figure}[H]
\begin{center}
\minipage{0.98\textwidth}
\includegraphics[width=0.9\textwidth]{hwaddmultcompare.png}
\endminipage
\caption{Comparison between HoltWinters multiplicative (left, red outline) and additive (right, green outline)algorithms, at some point during the research}
\end{center}
\end{figure}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Ireland-hw.pdf} \label{fig:ireland-hw}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Ireland-hwy.pdf} \label{fig:ireland-hwy}
\endminipage
\caption{HoltWinters model, Ireland}
\end{figure}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Italy-hw.pdf} \label{fig:italy-hw}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Italy-hwy.pdf} \label{fig:italy-hwy}
\endminipage
\caption{HoltWinters model, Italy}
\end{figure}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{United States-hw.pdf} \label{fig:usa-hw}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{United States-hwy.pdf} \label{fig:usa-hwy}
\endminipage
\caption{HoltWinters model, United States}
\end{figure}


\subsection{ARIMA models}

\subsubsection{Definitions and Theory}

\begin{definition}
The \textit{backshift operator} $B$ is a function on a time series $\left(x_n\right)_{n\geq1}$ such that $Bx_n=x_{n-1}$ and more genrerally:

$$B^k x_n= x_{n-k},\quad n>k$$

And similarly for the independent errors $\eps_n$:

$$B^k \eps_n= \eps_{n-k},\quad n>k$$
\end{definition}

We must first define the each component of a non-seasonal ARIMA model (suitable for time series with a trend).

\begin{itemize}
\item An $AR(p)$ model, or an autoregressive model of order $p$ of a time series $x_1,\dots,x_N$ states that each $x_n$ is a \textit{linear function} of $x_{n-p},x_{n-p+1},\dots,x_{n-1}$ and an error term, i.e. 
$$x_n= \phi_0+\phi_1 x_{n-1}+\phi_2 x_{n-2} +\dots + \phi_p x_{n-p}+\eps_n,\quad n>p,\quad \eps_n\sim N(0,\sigma^2)$$

We can simplify using the backshift operator $B$:

\begin{align}
x_n
&= \phi_0+\phi_1 Bx_n+\phi_2 B^2x_n +\dots + \phi_p B^px_n +\eps_n\nonumber \\
&= \phi_0+\left(\phi_1 B+\phi_2 B^2 +\dots + \phi_p B^p\right)x_n +\eps_n
\end{align}

\item An $MA(q)$ model, or a moving average model of order $q$ of a time series $x_1,\dots,x_N$ states that each $x_n$ is a \textit{linear function} of the $q$ previous errors $\eps_{n-q},\eps_{n-q+1},\dots,\eps_{n-1}$, plus the current error $\eps_n$, i.e. 
$$x_n= \psi_0-\psi_1 \eps_{n-1}-\psi_2 \eps_{n-2} -\dots - \psi_q \eps_{n-p}+\eps_n,\quad n>p$$

By convention we use minus signs in the coefficients $\psi_1,\dots,\psi_q$
We can simplify using the backshift operator $B$:

\begin{align}
x_n
&= \psi_0-\psi_1 B\eps_n-\psi_2 B^2\eps_n -\dots - \psi_q B^q\eps_n + \eps_n \nonumber \\
&= \psi_0+\left(1-\psi_1 B-\psi_2 B^2 +\dots - \psi_q B^q\right)\eps_n 
\end{align}

\item The first order differencing of the time series, $I(1)$, is evalueated as 

\begin{align}
x_n'
&=x_n-x_{n-1}\nonumber \\
&=x_n-Bx_n \nonumber \\
&=\left(1-B\right)x_n
\end{align}

More generally, the differencing of order $d$, denoted $I(d)$ is 
$$(1-B)^d x_n$$

This only affects the $x_n$ (although constants are differenced to zero) and the errors $\eps_n$ are unchanged.
\end{itemize}

Therefore, an ARIMA$(p,d,q)$ model can be evaluated by combining the $AR(p),\ I(d)$ and $MA(q)$

\begin{align}
(1-B)^d x_n
&= \phi_0+(1-B)^d\left(\phi_1 B+\phi_2 B^2 +\dots + \phi_p B^p\right)x_n +
\psi_0+\left(\psi_1 B+\psi_2 B^2 +\dots + \psi_q B^q\right)\eps_n \nonumber 
\end{align}

\begin{align}
(1-B)^d x_n + (1-B)^d\left(-\phi_1 B-\phi_2 B^2 -\dots - \phi_p B^p\right)x_n
&= \phi_0 + \psi_0+\left(1-\psi_1 B-\psi_2 B^2 +\dots - \psi_q B^q\right)\eps_n  \nonumber \\
(1-B)^d\left(1-\phi_1 B-\phi_2 B^2 -\dots - \phi_p B^p\right)x_n
&=c+\left(1-\psi_1 B-\psi_2 B^2 +\dots - \psi_q B^q\right)\eps_n  \nonumber \\
\end{align}

where $c= \phi_0 + \psi_0$ (it is zero if $d\geq1$).

We also need the seasonal components for an ARIMA$(p,d,q)(P,D,Q)_s$ 

Suppose a time series $x_n$ has period $s$ (seasonal pattern every $s$ values)
\begin{itemize}

\item An $AR(P)_s$ model, or a seasonal autoregressive model of order $P$ of a time series $x_1,\dots,x_N$ states that each $x_n$ is a \textit{linear function} of $x_{n-Ps},x_{n-(P-1)s},\dots,x_{n-s}$ and an error term, i.e. 
$$x_n= \beta_0+\beta_1 x_{n-s}+\beta_2 x_{n-2s} +\dots + \beta_P x_{n-Ps}+\eps_n$$

We can simplify using the backshift operator $B$:

\begin{align}
x_n &= \beta_0+\left(\beta_1 B^s+\beta_2 B^{2s} +\dots + \beta_P B^{Ps}\right)x_n
\end{align}

\item An $MA(Q)_s$ model, or a seasonal moving average model of order $Q$ of a time series $x_1,\dots,x_N$ states that each $x_n$ is a \textit{linear function} of the $Q$ errors $\eps_{n-Ws},\eps_{n-(Q-1)s},\dots,\eps_{n-s}$, plus the current error $\eps_n$, i.e. 
$$x_n= \gamma_0-\gamma_1 \eps_{n-s}-\gamma_2 \eps_{n-2s} -\dots - \gamma_Q \eps_{n-Qs}+\eps_n$$

Again, by convention we use minus signs in the coefficients $\gamma_1,\dots,\gamma_Q$

We can simplify using the backshift operator $B$:

\begin{align}
x_n
&= \gamma_0-\gamma_1 \eps_{n-s}-\gamma_2 \eps_{n-2s} -\dots - \gamma_Q \eps_{n-Qs}+\eps_n \nonumber \\
&= \gamma_0+\left(1-\gamma_1 B^s-\gamma_2 B^{2s} +\dots - \gamma_Q B^{Qs}\right)\eps_n 
\end{align}

\item The first order seasonal differencing of the time series, $I_s(1)$, is evalueated as 

$$x_n-x_{n-s}=\left(1-B^s\right)x_n$$

More generally, the seasonal differencing of order $D$, denoted $I_s(D)$ is 

$$(1-B^s)^D x_n$$

The purpose of this is to make the time series  stationary in mean
\end{itemize}


Then we can similarly compose our seasonal components with the previous ARIMA$(pd,q)$ to get the definition of an ARIMA$(p,d,q)(P,D,Q)_s$ model

\begin{align}
\underbrace{\left(1-\phi_1 B-\phi_2B^2-\dots-\phi_p B^p\right)}_{AR(p)}
\underbrace{\left(1-\beta_1 B^s-\beta_2B^{2s}-\dots-\beta_P B^{Ps}\right)}_{AR_s(P)} 
\underbrace{\left(1-B\right)^d}_{I(d)}\underbrace{\left(1-B^s\right)^D}_{I_s(D)}   x_n = \nonumber \\
 c+
\underbrace{\left(1-\psi_1 B-\psi_2B^2-\dots-\psi_q B^q\right)}_{MA(q)}
\underbrace{\left(1-\gamma_1 B^s-\gamma_2B^{2s}-\dots-\gamma_Q B^{Qs}\right)}_{MA_s(Q)} \eps_n
\end{align}

where the constant $c$ is some function of the constants $\phi_0,\psi_0,\beta_0$ and $\gamma_0$ 

\subsubsection{How to select the best model}

\subsubsection{Forecasting}

\subsubsection{Implementation in R}

\begin{lstlisting}[frame=single, caption = {Algorithm for ARIMA Model}]
#' dat_ts A time-series of the ovservations x_n
#' countrydat A data.frame with the required info to plot case numbers
#' modeldat A data.frame with model data to plot (has forecastlen more rows than countrydat)
#' cols A list of colours for plotting
#' labs A list of labels for plotting
#' forecastlen The forecast length 
#' q The parameter for the basic model, in order tohave statistical models comparable with mathematical models
#' prevcases The cumulative cases prior to the first day in the range of countrydat

    #lambda=0 ensures values stay positive
    auto.fit <- auto.arima(dat_ts, lambda = 0)
  
    getArmaModel <- function(arma, pdq = c(1,6,2), PDQ = c(3,7,4), s=5){
      return(paste0("ARIMA(", paste0(arma[pdq],collapse = ","), ")(",
                 paste0(arma[PDQ], collapse = ","), ")[", arma[s], "]"))
    }
  
    arima.fcst <- forecast(auto.fit, level = c(80, 95), h = forecastlen)
    arima.fcst$fitted[1:q] <- countrydat$xn[1:q]
  
    arimanorm <- modnorm(countrydat$xn,arima.fcst$fitted)
  
    arimalabs    <- getArmaModel(auto.fit$arma)
    abs$arima   <- paste0(arimalabs, ", ||x*-x||=", arimanorm)
    abs$arimapi <- "ARIMA 95% Prediction Interval"
    
    modeldat$arimaxn <- c(auto.fit$fitted, arima.fcst$mean)
    modeldat$arimalo <- c(auto.fit$fitted,arima.fcst$lower[,2])
    modeldat$arimahi <- c(auto.fit$fitted,arima.fcst$upper[,2])
  
    modeldat$arimaxn[1:q] <- countrydat$xn[1:q]
    modeldat$arimalo[1:q] <- countrydat$xn[1:q]
    modeldat$arimahi[1:q] <- countrydat$xn[1:q]
  
    modeldat$arimayn  <- xntoyn(modeldat$arimaxn) + prevcases
    modeldat$arimaylo <- xntoyn(modeldat$arimalo) + prevcases
    modeldat$arimayhi <- xntoyn(modeldat$arimahi) + prevcases

    labs$arimay  <- paste0(arimalabs, ", ||y*-y||=", modnorm(countrydat$yn,modeldat$arimayn[1:nrow(countrydat)]))
  
    plots[["arima"]]   <- plot_arima(countrydat, modeldat, cols, labs)
    plots[["arimay"]] <- plot_arimay(countrydat, modeldat, cols, labs)
\end{lstlisting}

and our plotting function for daily cases looks like the following

\begin{lstlisting}[frame=single, caption = {Plot ARIMA Model}]
plot_arima <- function(countrydat, modeldat, cols, labs){
  p <- ggplot(countrydat, binwidth = 0) + 
    geom_bar(aes(x = date, y = xn, fill = "actual"), stat = "identity") + 
    geom_ribbon(data = modeldat, aes(x = date, ymin = arimalo, ymax = arimahi, fill = "pi"), alpha = 0.5) +
    geom_point(data = modeldat, aes(x = date, y = arimaxn, colour = "arima")) + 
    geom_line(data = modeldat, aes(x = date, y = arimaxn, colour = "arima")) +
    geom_point(data = modeldat, aes(x = date, y = basexn, colour = "base")) + 
    geom_line(data = modeldat, aes(x = date, y = basexn, colour = "base")) +
    geom_point(data = modeldat,aes(x = date, y = periodic, colour = "periodic")) +
    geom_line(data = modeldat, aes(x = date, y = periodic, colour = "periodic")) +
    gg_scale_xy + 
    guides(colour=guide_legend(ncol=1,nrow=3,byrow=TRUE),
           fill=guide_legend(ncol=1,nrow=2,byrow=TRUE)) +
    scale_fill_manual(values = c("actual" = cols$xn, "pi" = cols$arimapi), 
                      labels = c("actual" = labs$xn, "pi" = labs$arimapi)) +
    scale_colour_manual(values = c("arima" = cols$arima, "base" = cols$basexn, "periodic" = cols$periodic), 
                        labels = c("arima" = labs$arima, "base" = labs$basexn, "periodic" = labs$periodic)) +
    xntheme()
  return(p)
}
\end{lstlisting}

\subsubsection{Plots}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Ireland-arima.pdf} \label{fig:ireland-arima}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Ireland-arimay.pdf} \label{fig:ireland-arimay}
\endminipage
\caption{ARIMA model, Ireland}
\end{figure}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Italy-arima.pdf} \label{fig:italy-arima}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Italy-arimay.pdf} \label{fig:italy-arimay}
\endminipage
\caption{ARIMA model, Italy}
\end{figure}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{United States-arima.pdf} \label{fig:usa-arima}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{United States-arimay.pdf} \label{fig:usa-arimay}
\endminipage
\caption{ARIMA model, United States}
\end{figure}

\subsection{Neural network models}

\begin{figure}[H]
\includegraphics[width=0.9\textwidth]{NeuralNetNoHidden.pdf}
\caption{A linear regression model, or ARIMA$(p,0,0)$ model.}
\end{figure}

\begin{figure}[H]
\includegraphics[width=0.9\textwidth]{NeuralNet.pdf}
\caption{A neural network with $p$ inputs and one hidden layer with $k$ hidden neurons.}
\end{figure}

\subsubsection{Definitions and Theory}

\subsubsection{How to select the best model}

\subsubsection{Forecasting}

\subsubsection{Implementation in R}

\begin{lstlisting}[frame=single, caption = {Algorithm for Neural Network Model}]
#' dat_ts A time-series of the ovservations x_n
#' countrydat A data.frame with the required info to plot case numbers
#' modeldat A data.frame with model data to plot (has forecastlen more rows than countrydat)
#' cols A list of colours for plotting
#' labs A list of labels for plotting
#' forecastlen The forecast length 
#' q The parameter for the basic model, in order tohave statistical models comparable with mathematical models
#' prevcases The cumulative cases prior to the first day in the range of countrydat

#requires arima auto.fit object from earlier
   nHidden <- max(1,floor(0.5*(1+auto.fit$arma[1]+auto.fit$arma[3])))
  #Box-Cox transformation with lambda=0 to ensure the forecasts stay positive.
  nnfit   <- nnetar(dat_ts, p = auto.fit$arma[1], P = auto.fit$arma[3], size = nHidden, lambda = 0, repeats = 20, maxit = 50) 
  nn.fcst <- forecast(nnfit, h = forecastlen)

  nn.fcst$mean[nn.fcst$mean < 0] <- 0
  nn.fcst$fitted[1:q] <- countrydat$xn[1:q]
 
  modeldat$nnxn <- c(nn.fcst$fitted, nn.fcst$mean)
  modeldat$nnyn <- xntoyn(modeldat$nnxn) + prevcases
  
  labs$nn  <- paste0(nnfit$method, ", ||x*-x||=", modnorm(countrydat$xn,nn.fcst$fitted))
  labs$nny <- paste0(nnfit$method, ", ||y*-y||=", modnorm(countrydat$yn,modeldat$nnyn[1:nrow(countrydat)]))
  
  plots[["nn"]] <- plot_nn(countrydat, modeldat, cols, labs)
  
  plots[["nny"]] <- plot_nny(countrydat, modeldat, cols, labs)
\end{lstlisting}

and our plotting function for daily cases looks like the following

\begin{lstlisting}[frame=single, caption = {Plot Neural Network Model}]
plot_nn <- function(countrydat, modeldat, cols, labs){
  p <- ggplot(countrydat, binwidth = 0) + 
    geom_bar(aes(x = date, y = xn, fill = "actual"), stat = "identity") + 
    geom_point(data = modeldat, aes(x = date, y = basexn, colour = "base")) + 
    geom_line(data = modeldat, aes(x = date, y = basexn, colour = "base")) +
    geom_point(data = modeldat,aes(x = date, y = periodic, colour = "periodic")) +
    geom_line(data = modeldat, aes(x = date, y = periodic, colour = "periodic")) +
    geom_point(data = modeldat, aes(x = date, y = nnxn, colour = "nn")) + 
    geom_line(data = modeldat, aes(x = date, y = nnxn, colour = "nn")) +
    gg_scale_xy + 
    guides(colour=guide_legend(ncol=1,nrow=3,byrow=TRUE),
           fill=guide_legend(ncol=1,nrow=1,byrow=TRUE)) +
    scale_fill_manual(values = c("actual" = cols$xn), 
                      labels = c("actual" = labs$xn)) +
    scale_colour_manual(values = c("base" = cols$basexn, "nn" = cols$nn, "periodic" = cols$periodic), 
                        labels = c("base" = labs$basexn, "nn" = labs$nn, "periodic" = labs$periodic)) +
    xntheme()
  return(p)
}
\end{lstlisting}

\subsubsection{Plots}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Ireland-nn.pdf} \label{fig:ireland-nn}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Ireland-nny.pdf} \label{fig:ireland-nny}
\endminipage
\caption{Neural Network model, Ireland}
\end{figure}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Italy-nn.pdf} \label{fig:italy-nn}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{Italy-nny.pdf} \label{fig:italy-nny}
\endminipage
\caption{Neural Network model, Italy}
\end{figure}

\begin{figure}[H]
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{United States-nn.pdf} \label{fig:usa-nn}
\endminipage\hfill
\minipage{0.48\textwidth}
  \includegraphics[width=\linewidth]{United States-nny.pdf} \label{fig:usa-nny}
\endminipage
\caption{Neural Network model, United States}
\end{figure}
